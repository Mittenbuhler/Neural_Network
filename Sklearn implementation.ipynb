{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing ANN using Lasagne/Theano package\n",
    "\n",
    "\n",
    "This code just provides a general framework for my project. I simply do the same but switch out the sklearn functions with my own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get MNIST data\n",
    "Before we start with the NN, we need to import the libraries etc. Most importantly, we need to load the training and test data that we use for the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import higher level libraries (these I should not use in the final project)\n",
    "import lasagne # package to build NNs\n",
    "import theano # package for md-array computation\n",
    "import theano.tensor as T\n",
    "\n",
    "#Set working directory\n",
    "os.chdir('/Users/Max/Documents/Studium/Master/Semester 2/Programming/Data')\n",
    "\n",
    "# Load datasets as np.arrays\n",
    "train_images = idx2numpy.convert_from_file('train-images.idx3-ubyte')\n",
    "train_labels = idx2numpy.convert_from_file('train-labels.idx1-ubyte')\n",
    "test_images = idx2numpy.convert_from_file('t10k-images.idx3-ubyte')\n",
    "test_labels = idx2numpy.convert_from_file('t10k-labels.idx1-ubyte')\n",
    "\n",
    "# Divide by 256 to get values between 0 and 1\n",
    "train_images = train_images/np.float32(256)\n",
    "test_images = test_images/np.float32(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADWxJREFUeJzt3X+MHPV9xvHn8XG2YycoHMTGAYMphagIqUd1MW0cqCsHRCoqg5JYsdTUlaJc/ghqkfIH1GoVqqgqiZoQ1ERIF7jGSAkkVULxHyQFrKgUFTk+KI2hpg0lBozdO6cmsgnGv+7TP24cHeZ2dr07u7Pnz/slWbc735mdRys/N7s3s/t1RAhAPgvqDgCgHpQfSIryA0lRfiApyg8kRfmBpCg/kBTlB5Ki/EBSZ/VyZwu9KBZraS93CaTyln6lo3HErazbUflt3yDpbkkDku6NiDvL1l+spbra6zrZJYAS22Nby+u2/bLf9oCkb0j6qKQrJG20fUW7jwegtzp5z79a0osR8VJEHJX0oKT11cQC0G2dlP8CSa/Our+nWPY2tkdtT9ieOKYjHewOQJU6Kf9cf1R4x+eDI2IsIkYiYmRQizrYHYAqdVL+PZJWzrp/oaS9ncUB0CudlH+HpMtsX2J7oaRPStpaTSwA3db2qb6IOG77Fkn/rJlTfeMR8XxlyQB0VUfn+SPiEUmPVJQFQA9xeS+QFOUHkqL8QFKUH0iK8gNJUX4gKcoPJEX5gaQoP5AU5QeSovxAUpQfSIryA0lRfiApyg8kRfmBpCg/kBTlB5Ki/EBSlB9IivIDSVF+ICnKDyRF+YGkKD+QFOUHkqL8QFKUH0iK8gNJdTRLr+3dkg5JOiHpeESMVBEKqMKvPn51w7Evffme0m2/uOFPSsdj4rm2MvWTjspf+IOI+EUFjwOgh3jZDyTVaflD0qO2n7Y9WkUgAL3R6cv+NRGx1/YySY/ZfiEinpi9QvFLYVSSFmtJh7sDUJWOjvwRsbf4OSXpIUmr51hnLCJGImJkUIs62R2ACrVdfttLbb/n5G1J10ua/38CBZLo5GX/ckkP2T75ON+JiB9VkgpA17Vd/oh4SdJvV5ilqw6vf8c7krePnztQOj40/lSVcdADUyONX9h+cfcf9TBJf+JUH5AU5QeSovxAUpQfSIryA0lRfiCpKj7VNy/svbb899ySS39Z/gDjFYZBNRaUn56Niw43HFu37IXSbbf5Q21Fmk848gNJUX4gKcoPJEX5gaQoP5AU5QeSovxAUmnO8//1jf9YOv6lXdf3KAmqMnDpxaXjL/x+44szhn/yx6Xbvn/HzrYyzScc+YGkKD+QFOUHkqL8QFKUH0iK8gNJUX4gqTTn+Qd9vO4IqNhZ977Z9raH/+fsCpPMTxz5gaQoP5AU5QeSovxAUpQfSIryA0lRfiCppuf5bY9LulHSVERcWSwbkvRdSask7Za0ISJe717M5qY/PFw6fs3iJ3uUBL2yaun/tb3tysdPVJhkfmrlyP8tSTecsux2Sdsi4jJJ24r7AOaRpuWPiCckHThl8XpJW4rbWyTdVHEuAF3W7nv+5RGxT5KKn8uqiwSgF7p+bb/tUUmjkrRYS7q9OwAtavfIP2l7hSQVP6carRgRYxExEhEjg1rU5u4AVK3d8m+VtKm4vUnSw9XEAdArTctv+wFJT0n6gO09tj8t6U5J19n+maTrivsA5pGm7/kjYmODoXUVZ+nIyze+q3R82QB/b5hvzlp1Uen4x4e2tv3Y7/p5+WUpGa4C4Ao/ICnKDyRF+YGkKD+QFOUHkqL8QFJnzFd3n/Wbhzra/q0X3ltRElTl1a8tLR1fs2i6dPy+gxc2HvzlwXYinVE48gNJUX4gKcoPJEX5gaQoP5AU5QeSovxAUmfMef5OLZsoP2eMuQ2cd27p+OTHLm84NrRhT+m2/3L5fU32vrh09J5vNP5e2WWT/9bksc98HPmBpCg/kBTlB5Ki/EBSlB9IivIDSVF+ICnO8xcOD5X/Hiz/ZHlnpq+5qnQ8Blw6/upHGs+EdPT9x0q3XbCw/EuqH73m70vHB8uj6X9PNM72Vy/dXLrtgenyay+WLCjPvnx74+94iNItc+DIDyRF+YGkKD+QFOUHkqL8QFKUH0iK8gNJNT3Pb3tc0o2SpiLiymLZHZI+I2l/sdrmiHikWyFbceStwdLx6SZndv9h812l41tvGT7tTK267dx7S8cXqPxk+uE42nBs74nyc+Ff37+2dPwjj99aOv7ef19YOr7i0cmGY365/PP8+3eVT7u+fKD8GobYsbN0PLtWjvzfknTDHMvviojh4l+txQdw+pqWPyKekHSgB1kA9FAn7/lvsf1T2+O2z6ksEYCeaLf890i6VNKwpH2SvtJoRdujtidsTxzTkTZ3B6BqbZU/IiYj4kRETEv6pqTVJeuORcRIRIwMqvGHPAD0Vlvlt71i1t2bJT1XTRwAvdLKqb4HJK2VdJ7tPZK+IGmt7WHNfDJyt6TPdjEjgC5wRO8+2Xy2h+Jqr+vZ/mb7+d/+Xun4yg++1qMkp2//D0vmmZd07vONz3cv/NGOquNU5rXbPlQ6/h9/9vXS8QffeF/p+P0fWHnamea77bFNB+NAk29ZmMEVfkBSlB9IivIDSVF+ICnKDyRF+YGk0nx19yV/8VTdEdq2Qq/UHaErlly7v/lKJf7yxx8rHb9cP+no8c90HPmBpCg/kBTlB5Ki/EBSlB9IivIDSVF+IKk05/lx5rn4YSba7gRHfiApyg8kRfmBpCg/kBTlB5Ki/EBSlB9IivIDSVF+ICnKDyRF+YGkKD+QFOUHkqL8QFKUH0iq6ef5ba+UdL+k8yVNSxqLiLttD0n6rqRVknZL2hARr3cvKrIZcPmx6fXLB0vHz/9hlWnOPK0c+Y9L+nxE/Jak35X0OdtXSLpd0raIuEzStuI+gHmiafkjYl9EPFPcPiRpl6QLJK2XtKVYbYukm7oVEkD1Tus9v+1Vkq6StF3S8ojYJ838gpC0rOpwALqn5fLbfrek70u6NSIOnsZ2o7YnbE8c05F2MgLogpbKb3tQM8X/dkT8oFg8aXtFMb5C0tRc20bEWESMRMTIoBZVkRlABZqW37Yl3SdpV0R8ddbQVkmbitubJD1cfTwA3dLKV3evkfQpSTttP1ss2yzpTknfs/1pSa9I+kR3IiKrEzFdvgJXqXSkafkj4klJbjC8rto4AHqF351AUpQfSIryA0lRfiApyg8kRfmBpJiiG/PWmx98s+4I8xpHfiApyg8kRfmBpCg/kBTlB5Ki/EBSlB9IivP86FvNvrobneHZBZKi/EBSlB9IivIDSVF+ICnKDyRF+YGkOM+P2hx5/H2l4yeGm3xvPzrCkR9IivIDSVF+ICnKDyRF+YGkKD+QFOUHknJElK9gr5R0v6TzJU1LGouIu23fIekzkvYXq26OiEfKHutsD8XVZlZvoFu2xzYdjANuZd1WLvI5LunzEfGM7fdIetr2Y8XYXRHxd+0GBVCfpuWPiH2S9hW3D9neJemCbgcD0F2n9Z7f9ipJV0naXiy6xfZPbY/bPqfBNqO2J2xPHNORjsICqE7L5bf9bknfl3RrRByUdI+kSyUNa+aVwVfm2i4ixiJiJCJGBrWogsgAqtBS+W0Paqb4346IH0hSRExGxImImJb0TUmruxcTQNWalt+2Jd0naVdEfHXW8hWzVrtZ0nPVxwPQLa38tX+NpE9J2mn72WLZZkkbbQ9LCkm7JX22KwkBdEUrf+1/UtJc5w1Lz+kD6G9c4QckRfmBpCg/kBTlB5Ki/EBSlB9IivIDSVF+ICnKDyRF+YGkKD+QFOUHkqL8QFKUH0iq6Vd3V7oze7+kl2ctOk/SL3oW4PT0a7Z+zSWRrV1VZrs4IsrnPi/0tPzv2Lk9EREjtQUo0a/Z+jWXRLZ21ZWNl/1AUpQfSKru8o/VvP8y/ZqtX3NJZGtXLdlqfc8PoD51H/kB1KSW8tu+wfZ/2X7R9u11ZGjE9m7bO20/a3ui5izjtqdsPzdr2ZDtx2z/rPg55zRpNWW7w/ZrxXP3rO0/rCnbSts/tr3L9vO2/7xYXutzV5Krluet5y/7bQ9I+m9J10naI2mHpI0R8Z89DdKA7d2SRiKi9nPCtq+V9Iak+yPiymLZlyUdiIg7i1+c50TEbX2S7Q5Jb9Q9c3MxocyK2TNLS7pJ0p+qxueuJNcG1fC81XHkXy3pxYh4KSKOSnpQ0voacvS9iHhC0oFTFq+XtKW4vUUz/3l6rkG2vhAR+yLimeL2IUknZ5au9bkryVWLOsp/gaRXZ93fo/6a8jskPWr7adujdYeZw/Ji2vST06cvqznPqZrO3NxLp8ws3TfPXTszXletjvLPNftPP51yWBMRvyPpo5I+V7y8RWtamrm5V+aYWbovtDvjddXqKP8eSStn3b9Q0t4acswpIvYWP6ckPaT+m3148uQkqcXPqZrz/Fo/zdw818zS6oPnrp9mvK6j/DskXWb7EtsLJX1S0tYacryD7aXFH2Jke6mk69V/sw9vlbSpuL1J0sM1Znmbfpm5udHM0qr5ueu3Ga9rucinOJXxNUkDksYj4m96HmIOtn9DM0d7aWYS0+/Umc32A5LWauZTX5OSviDpnyR9T9JFkl6R9ImI6Pkf3hpkW6uZl66/nrn55HvsHmf7sKR/lbRT0nSxeLNm3l/X9tyV5NqoGp43rvADkuIKPyApyg8kRfmBpCg/kBTlB5Ki/EBSlB9IivIDSf0/TW6uR+IFxrIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "plt.show(plt.imshow(train_images[2]))\n",
    "train_labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data format\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set-up NN\n",
    "\n",
    "With the high-level functions, we can simply define the attributes of the NN. We need to define the following:\n",
    "- Number of layers (2 hidden layers)\n",
    "- Number of nodes (800 in each hidden layer)\n",
    "- Output range (between 0 and 1)\n",
    "- Step size (0.01)\n",
    "- Momentum (0.9) - not necessary for stochastic gradient descent\n",
    "- Drop-out rates to avoid overfitting (20%/50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we write a function that builds the neural network with the attributes above\n",
    "# It takes one image ('input_var') as input, i.e. an array of size 28x28\n",
    "def build_NN(input_var=None):\n",
    "    # Set-up input layer:\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None,28,28), input_var=input_var)\n",
    "    l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.2) # drop 20% to avoid overfitting\n",
    "    \n",
    "    # Set-up first hidden layer:\n",
    "    l_hid1 = lasagne.layers.DenseLayer(l_in_drop, num_units=800, \n",
    "                                       nonlinearity=lasagne.nonlinearities.rectify, \n",
    "                                       W=lasagne.init.GlorotUniform()) # just default settings here\n",
    "    l_hid1_drop = lasagne.layers.DropoutLayer(l_hid1, p=0.5) # drop 50%\n",
    "    \n",
    "    # Set-up second hidden layer (same procedure as first hidden layer):\n",
    "    l_hid2 = lasagne.layers.DenseLayer(l_hid1_drop, num_units=800, \n",
    "                                       nonlinearity=lasagne.nonlinearities.rectify, \n",
    "                                       W=lasagne.init.GlorotUniform()) # just default settings here\n",
    "    l_hid2_drop = lasagne.layers.DropoutLayer(l_hid2, p=0.5) # drop 50%\n",
    "    \n",
    "    # Set-up output layer:\n",
    "    l_out = lasagne.layers.DenseLayer(l_hid2_drop, num_units=10, \n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax) #'softmax' puts numbers between 0 and 1\n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, we need to tell the NN we've just set up, how to train itself (how to update the weights)\n",
    "# To do that we need some place-holder input:\n",
    "input_var = T.tensor3('inputs') # empty 3d-array\n",
    "target_var = T.ivector('targets') # empty integer vector\n",
    "\n",
    "# Build NN with these place-holders:\n",
    "network = build_NN(input_var)\n",
    "\n",
    "# Set-up training algorithm:\n",
    "# 1. Compute loss:\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var) # cross entropy is standard loss function\n",
    "loss = loss.mean()\n",
    "\n",
    "# 2. Update weights (based on loss):\n",
    "weights = lasagne.layers.get_all_params(network, trainable=True) # current value of all weights\n",
    "updates = lasagne.updates.nesterov_momentum(loss, weights, learning_rate = 0.01, momentum = 0.9) # step at each iteration\n",
    "# nesterov-momentum is a fancy version of stochastic gradient descent\n",
    "\n",
    "# 3. Put everything together into a single training step:\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train NN\n",
    "We have defined all the necessary attributes of the NN. Now, we need to feed it with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Step: 10\n",
      "Step: 11\n",
      "Step: 12\n",
      "Step: 13\n",
      "Step: 14\n",
      "Step: 15\n",
      "Step: 16\n",
      "Step: 17\n",
      "Step: 18\n",
      "Step: 19\n",
      "Step: 20\n",
      "Step: 21\n",
      "Step: 22\n",
      "Step: 23\n",
      "Step: 24\n"
     ]
    }
   ],
   "source": [
    "n_iter = 25 # number of training steps, should be more! (just to check)\n",
    "for step in range(n_iter):\n",
    "    train_err = train_fn(train_images, train_labels)\n",
    "    print('Step: ' + str(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test NN\n",
    "Now, that we have a (hopefully) functioning neural network, we can test it on the training data. Before that, we can look at the output of it to see if it is roughly working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04993272, 0.08809271, 0.07758057, 0.09077275, 0.05088764,\n",
       "        0.06416025, 0.09121133, 0.34508851, 0.02135494, 0.12091858]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the ouput for one test image and see if its correct:\n",
    "test_prediction = lasagne.layers.get_output(network) # function to retreive output layer from network\n",
    "val_fn = theano.function([input_var], test_prediction) # function to run one image through the network and return output\n",
    "\n",
    "val_fn([test_images[0]]) # Output for the first image in the test set; from the probabilities you can tell \n",
    "# that the NN is not really confident (highest probability for number 7, but only about 26%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.7869)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check accuracy over whole test set:\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic = True)\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var), dtype=theano.config.floatX)\n",
    "# This function matches the index of the highest value with the label and gets the mean over the complete input\n",
    "\n",
    "acc_fn = theano.function([input_var, target_var], test_acc) # function to feed dataset\n",
    "\n",
    "# Test NN on test set, return accuracy\n",
    "acc_fn(test_images, test_labels) # 80% after 25 iterations, not bad\n",
    "# could be improved by using batches of data and more iterations (and improving attributes like step size etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
